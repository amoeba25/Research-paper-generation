{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Soham Shah\n",
    "### J059"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "0CcmOzilOu23"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ishanishah/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "pd.set_option(\"display.max_colwidth\", 200)\n",
    "from gensim.models import Word2Vec\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "nltk.download('wordnet')\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "pyLDAvis.enable_notebook()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "hCi_22TZO_BO"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('papers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "bR3M0RjVSRle"
   },
   "outputs": [],
   "source": [
    "data = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 284
    },
    "id": "tBffeJ6zUfnV",
    "outputId": "935a4a7e-41af-42e7-96a2-0fe65482ea21"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>year</th>\n",
       "      <th>title</th>\n",
       "      <th>event_type</th>\n",
       "      <th>pdf_name</th>\n",
       "      <th>abstract</th>\n",
       "      <th>paper_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4261</th>\n",
       "      <td>4857</td>\n",
       "      <td>2013</td>\n",
       "      <td>Scalable Influence Estimation in Continuous-Time Diffusion Networks</td>\n",
       "      <td>Oral</td>\n",
       "      <td>4857-scalable-influence-estimation-in-continuous-time-diffusion-networks.pdf</td>\n",
       "      <td>If a piece of information is released from a media site, can it spread, in 1 month, to a million web pages? This influence estimation problem is very challenging since both the time-sensitive natu...</td>\n",
       "      <td>Scalable Influence Estimation in\\nContinuous-Time Diffusion Networks\\nNan Du?\\nLe Song?\\nManuel Gomez-Rodriguez?\\nHongyuan Zha?\\n?\\nGeorgia Institute of Technology\\nMPI for Intelligent Systems?\\nd...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  year  \\\n",
       "4261  4857  2013   \n",
       "\n",
       "                                                                    title  \\\n",
       "4261  Scalable Influence Estimation in Continuous-Time Diffusion Networks   \n",
       "\n",
       "     event_type  \\\n",
       "4261       Oral   \n",
       "\n",
       "                                                                          pdf_name  \\\n",
       "4261  4857-scalable-influence-estimation-in-continuous-time-diffusion-networks.pdf   \n",
       "\n",
       "                                                                                                                                                                                                     abstract  \\\n",
       "4261  If a piece of information is released from a media site, can it spread, in 1 month, to a million web pages? This influence estimation problem is very challenging since both the time-sensitive natu...   \n",
       "\n",
       "                                                                                                                                                                                                   paper_text  \n",
       "4261  Scalable Influence Estimation in\\nContinuous-Time Diffusion Networks\\nNan Du?\\nLe Song?\\nManuel Gomez-Rodriguez?\\nHongyuan Zha?\\n?\\nGeorgia Institute of Technology\\nMPI for Intelligent Systems?\\nd...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V5CvOk6yUkVp",
    "outputId": "c5d11cc6-d3c9-4e84-8e46-60bfef8dc840"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id            0\n",
       "year          0\n",
       "title         0\n",
       "event_type    0\n",
       "pdf_name      0\n",
       "abstract      0\n",
       "paper_text    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_text = data[['paper_text']]\n",
    "data_text['index'] = data_text.index\n",
    "documents = data_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_text</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4261</th>\n",
       "      <td>Scalable Influence Estimation in\\nContinuous-Time Diffusion Networks\\nNan Du?\\nLe Song?\\nManuel Gomez-Rodriguez?\\nHongyuan Zha?\\n?\\nGeorgia Institute of Technology\\nMPI for Intelligent Systems?\\nd...</td>\n",
       "      <td>4261</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                   paper_text  \\\n",
       "4261  Scalable Influence Estimation in\\nContinuous-Time Diffusion Networks\\nNan Du?\\nLe Song?\\nManuel Gomez-Rodriguez?\\nHongyuan Zha?\\n?\\nGeorgia Institute of Technology\\nMPI for Intelligent Systems?\\nd...   \n",
       "\n",
       "      index  \n",
       "4261   4261  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2422"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_stemming(text):\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
    "\n",
    "def preprocess(text):\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "            result.append(lemmatize_stemming(token))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_sample = documents[documents['index'] == 4310].values[0][0]\n",
    "\n",
    "words = []\n",
    "for word in doc_sample.split(' '):\n",
    "    words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_docs = documents['paper_text'].map(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4261    [scalabl, influenc, estim, continu, time, diffus, network, song, manuel, gomez, rodriguez, hongyuan, georgia, institut, technolog, intellig, system, dunan, gatech, lsong, gatech, manuelgr, gatech,...\n",
       "4262    [adapt, anonym, match, krzysztof, choromanski, columbia, univers, columbia, toni, jebara, columbia, univers, columbia, tang, columbia, univers, columbia, abstract, adapt, anonym, problem, formal, ...\n",
       "4263    [exact, stabl, recoveri, pairwis, interact, tensor, shouyuan, chen, michael, irwin, king, chines, univers, hong, kong, sychen, king, cuhk, zenglin, purdu, univers, purdu, abstract, tensor, complet...\n",
       "4265    [matrix, factor, binari, compon, martin, slawski, matthia, hein, pavlo, lutsik, saarland, univers, hein, saarland, lutsik, saarland, abstract, motiv, applic, comput, biolog, consid, rank, matrix, ...\n",
       "4266    [complex, approxim, binari, evid, lift, infer, broeck, adnan, darwich, scienc, depart, univers, california, angel, guyvdb, darwich, ucla, abstract, lift, infer, algorithm, exploit, symmetri, proba...\n",
       "4267    [unsupervis, spectral, learn, fsts, rapha, bailli, xavier, carrera, ariadna, quattoni, universitat, politecnica, catalunya, barcelona, rbailli, carrera, aquattoni, abstract, finit, state, transduc...\n",
       "4268    [decompos, proxim, yaoliang, depart, comput, scienc, univers, alberta, edmonton, canada, yaoliang, ualberta, abstract, proxim, step, gradient, type, algorithm, preval, larg, scale, high, dimension...\n",
       "4269    [uniform, camera, shake, remov, spatial, adapt, spars, penalti, haichao, zhang, david, wipf, school, scienc, northwestern, polytechn, univers, china, depart, electr, engin, duke, univers, visual, ...\n",
       "4270    [provabl, subspac, cluster, meet, xiang, wang, school, scienc, carnegi, mellon, univers, pittsburgh, yuxiangw, huan, dept, mech, engin, nation, univ, singapor, singapor, mpexuh, chenlei, leng, dep...\n",
       "4271    [matrix, complet, give, observ, troy, nanyang, technolog, univers, centr, quantum, technolog, troyjle, gmail, shraibman, depart, scienc, aviv, yaffo, academ, colleg, shribman, gmail, abstract, mat...\n",
       "Name: paper_text, dtype: object"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_docs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = gensim.corpora.Dictionary(processed_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 absolut\n",
      "1 abstract\n",
      "2 accumul\n",
      "3 accur\n",
      "4 accuraci\n",
      "5 achiev\n",
      "6 acknowledg\n",
      "7 actual\n",
      "8 acycl\n",
      "9 adapt\n",
      "10 add\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for k, v in dictionary.iteritems():\n",
    "    print(k, v)\n",
    "    count += 1\n",
    "    if count > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary.filter_extremes(no_below=15, no_above=0.5, keep_n=len(documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word 2 (\"accur\") appears 1 time.\n",
      "Word 6 (\"address\") appears 1 time.\n",
      "Word 7 (\"adopt\") appears 9 time.\n",
      "Word 14 (\"appendix\") appears 2 time.\n",
      "Word 19 (\"argument\") appears 2 time.\n",
      "Word 21 (\"artifici\") appears 3 time.\n",
      "Word 29 (\"binari\") appears 3 time.\n",
      "Word 31 (\"cambridg\") appears 1 time.\n",
      "Word 32 (\"captur\") appears 7 time.\n",
      "Word 37 (\"chen\") appears 1 time.\n",
      "Word 40 (\"collect\") appears 1 time.\n",
      "Word 44 (\"context\") appears 1 time.\n",
      "Word 59 (\"difficult\") appears 2 time.\n",
      "Word 69 (\"easi\") appears 1 time.\n",
      "Word 70 (\"easili\") appears 1 time.\n",
      "Word 77 (\"entir\") appears 2 time.\n",
      "Word 85 (\"exponenti\") appears 2 time.\n",
      "Word 95 (\"flexibl\") appears 1 time.\n",
      "Word 97 (\"formul\") appears 7 time.\n",
      "Word 101 (\"furthermor\") appears 1 time.\n",
      "Word 102 (\"gain\") appears 2 time.\n",
      "Word 112 (\"greater\") appears 1 time.\n",
      "Word 120 (\"heurist\") appears 3 time.\n",
      "Word 121 (\"hide\") appears 3 time.\n",
      "Word 130 (\"infinit\") appears 1 time.\n",
      "Word 136 (\"intuit\") appears 2 time.\n",
      "Word 137 (\"invari\") appears 3 time.\n",
      "Word 138 (\"investig\") appears 4 time.\n",
      "Word 139 (\"jmlr\") appears 2 time.\n",
      "Word 140 (\"joint\") appears 11 time.\n",
      "Word 142 (\"kernel\") appears 14 time.\n",
      "Word 146 (\"label\") appears 26 time.\n",
      "Word 148 (\"later\") appears 1 time.\n",
      "Word 149 (\"length\") appears 1 time.\n",
      "Word 152 (\"literatur\") appears 1 time.\n",
      "Word 159 (\"margin\") appears 19 time.\n",
      "Word 161 (\"markov\") appears 1 time.\n",
      "Word 162 (\"match\") appears 3 time.\n",
      "Word 166 (\"methodolog\") appears 1 time.\n",
      "Word 173 (\"mixtur\") appears 2 time.\n",
      "Word 184 (\"nest\") appears 2 time.\n",
      "Word 195 (\"occur\") appears 1 time.\n",
      "Word 197 (\"outer\") appears 1 time.\n",
      "Word 198 (\"overal\") appears 3 time.\n",
      "Word 200 (\"parallel\") appears 1 time.\n",
      "Word 207 (\"perspect\") appears 3 time.\n",
      "Word 213 (\"proc\") appears 4 time.\n",
      "Word 216 (\"program\") appears 1 time.\n",
      "Word 220 (\"qualiti\") appears 4 time.\n",
      "Word 223 (\"question\") appears 1 time.\n",
      "Word 225 (\"rank\") appears 6 time.\n",
      "Word 227 (\"recov\") appears 3 time.\n",
      "Word 233 (\"return\") appears 2 time.\n",
      "Word 237 (\"rich\") appears 1 time.\n",
      "Word 239 (\"round\") appears 2 time.\n",
      "Word 243 (\"search\") appears 2 time.\n",
      "Word 244 (\"seek\") appears 1 time.\n",
      "Word 253 (\"simpli\") appears 5 time.\n",
      "Word 257 (\"slight\") appears 1 time.\n",
      "Word 259 (\"smallest\") appears 1 time.\n",
      "Word 264 (\"spars\") appears 7 time.\n",
      "Word 265 (\"special\") appears 1 time.\n",
      "Word 269 (\"split\") appears 1 time.\n",
      "Word 283 (\"synthet\") appears 4 time.\n",
      "Word 294 (\"transform\") appears 5 time.\n",
      "Word 306 (\"util\") appears 1 time.\n",
      "Word 320 (\"zhang\") appears 3 time.\n",
      "Word 323 (\"abil\") appears 1 time.\n",
      "Word 325 (\"accept\") appears 1 time.\n",
      "Word 327 (\"accommod\") appears 4 time.\n",
      "Word 329 (\"admit\") appears 1 time.\n",
      "Word 336 (\"appear\") appears 1 time.\n",
      "Word 337 (\"archiv\") appears 1 time.\n",
      "Word 343 (\"automat\") appears 1 time.\n",
      "Word 344 (\"belief\") appears 2 time.\n",
      "Word 346 (\"benchmark\") appears 1 time.\n",
      "Word 351 (\"break\") appears 1 time.\n",
      "Word 360 (\"cluster\") appears 10 time.\n",
      "Word 361 (\"code\") appears 3 time.\n",
      "Word 368 (\"concern\") appears 1 time.\n",
      "Word 375 (\"correct\") appears 2 time.\n",
      "Word 376 (\"creat\") appears 1 time.\n",
      "Word 378 (\"criterion\") appears 1 time.\n",
      "Word 380 (\"desir\") appears 2 time.\n",
      "Word 382 (\"discov\") appears 2 time.\n",
      "Word 383 (\"discoveri\") appears 2 time.\n",
      "Word 384 (\"disjoint\") appears 1 time.\n",
      "Word 386 (\"drop\") appears 3 time.\n",
      "Word 389 (\"ensur\") appears 1 time.\n",
      "Word 390 (\"exploit\") appears 6 time.\n",
      "Word 396 (\"famili\") appears 1 time.\n",
      "Word 403 (\"foundat\") appears 2 time.\n",
      "Word 406 (\"group\") appears 5 time.\n",
      "Word 407 (\"grow\") appears 2 time.\n",
      "Word 409 (\"handl\") appears 1 time.\n",
      "Word 415 (\"http\") appears 4 time.\n",
      "Word 418 (\"identifi\") appears 1 time.\n",
      "Word 422 (\"intermedi\") appears 3 time.\n",
      "Word 424 (\"issu\") appears 1 time.\n",
      "Word 432 (\"lemma\") appears 12 time.\n",
      "Word 436 (\"maintain\") appears 1 time.\n",
      "Word 439 (\"maxi\") appears 4 time.\n",
      "Word 443 (\"necessari\") appears 1 time.\n",
      "Word 445 (\"offer\") appears 1 time.\n",
      "Word 447 (\"part\") appears 1 time.\n",
      "Word 455 (\"polynomi\") appears 2 time.\n",
      "Word 456 (\"poor\") appears 1 time.\n",
      "Word 458 (\"portion\") appears 1 time.\n",
      "Word 462 (\"preserv\") appears 6 time.\n",
      "Word 463 (\"prevent\") appears 1 time.\n",
      "Word 467 (\"probabilist\") appears 2 time.\n",
      "Word 476 (\"reduct\") appears 2 time.\n",
      "Word 477 (\"redund\") appears 1 time.\n",
      "Word 479 (\"regress\") appears 1 time.\n",
      "Word 480 (\"relationship\") appears 2 time.\n",
      "Word 481 (\"relax\") appears 25 time.\n",
      "Word 486 (\"saul\") appears 1 time.\n",
      "Word 488 (\"scenario\") appears 1 time.\n",
      "Word 494 (\"specifi\") appears 1 time.\n",
      "Word 496 (\"srivastava\") appears 1 time.\n",
      "Word 504 (\"supplement\") appears 1 time.\n",
      "Word 512 (\"tradit\") appears 4 time.\n",
      "Word 514 (\"treat\") appears 1 time.\n",
      "Word 515 (\"trivial\") appears 3 time.\n",
      "Word 520 (\"understand\") appears 1 time.\n",
      "Word 524 (\"unknown\") appears 2 time.\n",
      "Word 526 (\"usual\") appears 1 time.\n",
      "Word 527 (\"variat\") appears 1 time.\n",
      "Word 528 (\"versa\") appears 1 time.\n",
      "Word 529 (\"versus\") appears 3 time.\n",
      "Word 531 (\"vertic\") appears 1 time.\n",
      "Word 532 (\"vice\") appears 1 time.\n",
      "Word 535 (\"weaker\") appears 1 time.\n",
      "Word 541 (\"aaai\") appears 1 time.\n",
      "Word 551 (\"attent\") appears 1 time.\n",
      "Word 553 (\"avoid\") appears 2 time.\n",
      "Word 558 (\"believ\") appears 1 time.\n",
      "Word 564 (\"boyd\") appears 2 time.\n",
      "Word 565 (\"cand\") appears 1 time.\n",
      "Word 574 (\"column\") appears 3 time.\n",
      "Word 578 (\"conduct\") appears 4 time.\n",
      "Word 579 (\"cone\") appears 1 time.\n",
      "Word 583 (\"convex\") appears 45 time.\n",
      "Word 587 (\"decompos\") appears 1 time.\n",
      "Word 588 (\"decomposit\") appears 1 time.\n",
      "Word 590 (\"descript\") appears 1 time.\n",
      "Word 591 (\"determinist\") appears 1 time.\n",
      "Word 594 (\"dhillon\") appears 1 time.\n",
      "Word 595 (\"diag\") appears 7 time.\n",
      "Word 598 (\"encod\") appears 8 time.\n",
      "Word 599 (\"energi\") appears 1 time.\n",
      "Word 624 (\"interior\") appears 1 time.\n",
      "Word 633 (\"latent\") appears 61 time.\n",
      "Word 634 (\"letter\") appears 4 time.\n",
      "Word 640 (\"matric\") appears 4 time.\n",
      "Word 641 (\"meaning\") appears 1 time.\n",
      "Word 647 (\"norm\") appears 1 time.\n",
      "Word 657 (\"phase\") appears 1 time.\n",
      "Word 661 (\"pontil\") appears 1 time.\n",
      "Word 667 (\"promis\") appears 1 time.\n",
      "Word 669 (\"proport\") appears 2 time.\n",
      "Word 674 (\"recht\") appears 1 time.\n",
      "Word 676 (\"reconstruct\") appears 1 time.\n",
      "Word 678 (\"reformul\") appears 9 time.\n",
      "Word 694 (\"semi\") appears 1 time.\n",
      "Word 702 (\"signal\") appears 1 time.\n",
      "Word 703 (\"simplic\") appears 4 time.\n",
      "Word 704 (\"simul\") appears 1 time.\n",
      "Word 712 (\"subject\") appears 1 time.\n",
      "Word 713 (\"subsequ\") appears 1 time.\n",
      "Word 721 (\"trend\") appears 3 time.\n",
      "Word 725 (\"unlik\") appears 2 time.\n",
      "Word 727 (\"varieti\") appears 1 time.\n",
      "Word 728 (\"verifi\") appears 1 time.\n",
      "Word 730 (\"visual\") appears 1 time.\n",
      "Word 736 (\"affin\") appears 1 time.\n",
      "Word 747 (\"bach\") appears 2 time.\n",
      "Word 751 (\"banerje\") appears 1 time.\n",
      "Word 758 (\"boolean\") appears 2 time.\n",
      "Word 771 (\"concept\") appears 2 time.\n",
      "Word 780 (\"denois\") appears 1 time.\n",
      "Word 782 (\"despit\") appears 4 time.\n",
      "Word 790 (\"elimin\") appears 1 time.\n",
      "Word 793 (\"establish\") appears 6 time.\n",
      "Word 795 (\"expens\") appears 1 time.\n",
      "Word 797 (\"fail\") appears 1 time.\n",
      "Word 806 (\"ghosh\") appears 1 time.\n",
      "Word 807 (\"global\") appears 3 time.\n",
      "Word 809 (\"great\") appears 1 time.\n",
      "Word 813 (\"impos\") appears 5 time.\n",
      "Word 820 (\"interv\") appears 1 time.\n",
      "Word 821 (\"intract\") appears 3 time.\n",
      "Word 822 (\"invers\") appears 2 time.\n",
      "Word 833 (\"mind\") appears 1 time.\n",
      "Word 835 (\"modif\") appears 1 time.\n",
      "Word 836 (\"neal\") appears 1 time.\n",
      "Word 842 (\"outlin\") appears 1 time.\n",
      "Word 851 (\"pose\") appears 1 time.\n",
      "Word 852 (\"princip\") appears 2 time.\n",
      "Word 853 (\"principl\") appears 2 time.\n",
      "Word 862 (\"refin\") appears 1 time.\n",
      "Word 866 (\"robust\") appears 1 time.\n",
      "Word 869 (\"scheme\") appears 3 time.\n",
      "Word 877 (\"simplex\") appears 1 time.\n",
      "Word 878 (\"smooth\") appears 3 time.\n",
      "Word 882 (\"sparsiti\") appears 1 time.\n",
      "Word 883 (\"stack\") appears 1 time.\n",
      "Word 886 (\"strategi\") appears 3 time.\n",
      "Word 888 (\"submatrix\") appears 1 time.\n",
      "Word 899 (\"tractabl\") appears 2 time.\n",
      "Word 900 (\"tran\") appears 1 time.\n",
      "Word 907 (\"wise\") appears 3 time.\n",
      "Word 910 (\"advantag\") appears 7 time.\n",
      "Word 916 (\"balanc\") appears 1 time.\n",
      "Word 917 (\"behav\") appears 1 time.\n",
      "Word 924 (\"caus\") appears 3 time.\n",
      "Word 926 (\"classic\") appears 3 time.\n",
      "Word 927 (\"classif\") appears 11 time.\n",
      "Word 928 (\"classifi\") appears 2 time.\n",
      "Word 937 (\"deep\") appears 10 time.\n",
      "Word 938 (\"depart\") appears 1 time.\n",
      "Word 939 (\"diverg\") appears 2 time.\n",
      "Word 940 (\"divid\") appears 3 time.\n",
      "Word 945 (\"extract\") appears 1 time.\n",
      "Word 949 (\"fold\") appears 1 time.\n",
      "Word 955 (\"implicit\") appears 2 time.\n",
      "Word 970 (\"overcom\") appears 1 time.\n",
      "Word 972 (\"parameter\") appears 1 time.\n",
      "Word 979 (\"receiv\") appears 1 time.\n",
      "Word 996 (\"think\") appears 2 time.\n",
      "Word 997 (\"trade\") appears 1 time.\n",
      "Word 998 (\"transfer\") appears 5 time.\n",
      "Word 999 (\"unfortun\") appears 6 time.\n",
      "Word 1000 (\"unsupervis\") appears 4 time.\n",
      "Word 1013 (\"baselin\") appears 1 time.\n",
      "Word 1015 (\"build\") appears 1 time.\n",
      "Word 1018 (\"dean\") appears 1 time.\n",
      "Word 1021 (\"discrimin\") appears 1 time.\n",
      "Word 1028 (\"forward\") appears 1 time.\n",
      "Word 1036 (\"hilbert\") appears 1 time.\n",
      "Word 1039 (\"kakad\") appears 2 time.\n",
      "Word 1042 (\"longer\") appears 1 time.\n",
      "Word 1046 (\"parikh\") appears 1 time.\n",
      "Word 1048 (\"realist\") appears 1 time.\n",
      "Word 1051 (\"spectral\") appears 2 time.\n",
      "Word 1056 (\"supervis\") appears 4 time.\n",
      "Word 1057 (\"target\") appears 2 time.\n",
      "Word 1069 (\"canada\") appears 1 time.\n",
      "Word 1071 (\"cheng\") appears 1 time.\n",
      "Word 1074 (\"cod\") appears 3 time.\n",
      "Word 1076 (\"composit\") appears 1 time.\n",
      "Word 1084 (\"encourag\") appears 4 time.\n",
      "Word 1085 (\"enjoy\") appears 1 time.\n",
      "Word 1087 (\"exhibit\") appears 2 time.\n",
      "Word 1096 (\"hybrid\") appears 1 time.\n",
      "Word 1097 (\"immedi\") appears 1 time.\n",
      "Word 1109 (\"let\") appears 1 time.\n",
      "Word 1115 (\"minor\") appears 1 time.\n",
      "Word 1120 (\"nesterov\") appears 1 time.\n",
      "Word 1126 (\"predictor\") appears 1 time.\n",
      "Word 1142 (\"singer\") appears 1 time.\n",
      "Word 1146 (\"suitabl\") appears 1 time.\n",
      "Word 1161 (\"activ\") appears 5 time.\n",
      "Word 1171 (\"augment\") appears 5 time.\n",
      "Word 1172 (\"auxiliari\") appears 1 time.\n",
      "Word 1176 (\"boost\") appears 8 time.\n",
      "Word 1189 (\"cvpr\") appears 1 time.\n",
      "Word 1196 (\"dictionari\") appears 1 time.\n",
      "Word 1204 (\"emb\") appears 3 time.\n",
      "Word 1206 (\"enhanc\") appears 2 time.\n",
      "Word 1210 (\"facilit\") appears 1 time.\n",
      "Word 1229 (\"likelihood\") appears 2 time.\n",
      "Word 1231 (\"mach\") appears 3 time.\n",
      "Word 1237 (\"nation\") appears 1 time.\n",
      "Word 1245 (\"primari\") appears 3 time.\n",
      "Word 1251 (\"relev\") appears 1 time.\n",
      "Word 1252 (\"reproduc\") appears 1 time.\n",
      "Word 1255 (\"respons\") appears 7 time.\n",
      "Word 1257 (\"retain\") appears 2 time.\n",
      "Word 1266 (\"simplifi\") appears 2 time.\n",
      "Word 1270 (\"stage\") appears 5 time.\n",
      "Word 1276 (\"translat\") appears 1 time.\n",
      "Word 1284 (\"admm\") appears 3 time.\n",
      "Word 1286 (\"bodi\") appears 1 time.\n",
      "Word 1296 (\"elad\") appears 1 time.\n",
      "Word 1299 (\"euclidean\") appears 1 time.\n",
      "Word 1311 (\"multipli\") appears 3 time.\n",
      "Word 1327 (\"text\") appears 1 time.\n",
      "Word 1335 (\"weak\") appears 1 time.\n",
      "Word 1342 (\"eigenvalu\") appears 1 time.\n",
      "Word 1350 (\"semidefinit\") appears 7 time.\n",
      "Word 1352 (\"unobserv\") appears 1 time.\n",
      "Word 1354 (\"acceler\") appears 2 time.\n",
      "Word 1355 (\"acquir\") appears 1 time.\n",
      "Word 1356 (\"adequ\") appears 1 time.\n",
      "Word 1357 (\"anandkumar\") appears 1 time.\n",
      "Word 1358 (\"architectur\") appears 9 time.\n",
      "Word 1359 (\"arithmet\") appears 1 time.\n",
      "Word 1360 (\"auto\") appears 6 time.\n",
      "Word 1361 (\"autoencod\") appears 1 time.\n",
      "Word 1362 (\"bengio\") appears 3 time.\n",
      "Word 1363 (\"bird\") appears 1 time.\n",
      "Word 1364 (\"boltzmann\") appears 2 time.\n",
      "Word 1365 (\"book\") appears 1 time.\n",
      "Word 1366 (\"bottleneck\") appears 3 time.\n",
      "Word 1367 (\"box\") appears 2 time.\n",
      "Word 1368 (\"bregman\") appears 2 time.\n",
      "Word 1369 (\"calibr\") appears 1 time.\n",
      "Word 1370 (\"capac\") appears 1 time.\n",
      "Word 1371 (\"chapell\") appears 2 time.\n",
      "Word 1372 (\"cifar\") appears 5 time.\n",
      "Word 1373 (\"clarifi\") appears 1 time.\n",
      "Word 1374 (\"cognit\") appears 1 time.\n",
      "Word 1375 (\"comp\") appears 1 time.\n",
      "Word 1376 (\"compet\") appears 1 time.\n",
      "Word 1377 (\"competit\") appears 1 time.\n",
      "Word 1378 (\"concurr\") appears 2 time.\n",
      "Word 1379 (\"conf\") appears 1 time.\n",
      "Word 1380 (\"connectionist\") appears 1 time.\n",
      "Word 1381 (\"contract\") appears 1 time.\n",
      "Word 1382 (\"cope\") appears 2 time.\n",
      "Word 1383 (\"corrado\") appears 1 time.\n",
      "Word 1384 (\"cross\") appears 1 time.\n",
      "Word 1385 (\"decoupl\") appears 1 time.\n",
      "Word 1386 (\"depict\") appears 1 time.\n",
      "Word 1387 (\"devin\") appears 1 time.\n",
      "Word 1388 (\"difficulti\") appears 5 time.\n",
      "Word 1389 (\"discrep\") appears 1 time.\n",
      "Word 1390 (\"eigenvector\") appears 1 time.\n",
      "Word 1391 (\"exceed\") appears 1 time.\n",
      "Word 1392 (\"fee\") appears 1 time.\n",
      "Word 1393 (\"freita\") appears 1 time.\n",
      "Word 1394 (\"goldberg\") appears 1 time.\n",
      "Word 1395 (\"hinton\") appears 2 time.\n",
      "Word 1396 (\"html\") appears 2 time.\n",
      "Word 1397 (\"innov\") appears 1 time.\n",
      "Word 1398 (\"inter\") appears 1 time.\n",
      "Word 1399 (\"joachim\") appears 1 time.\n",
      "Word 1400 (\"lagrangian\") appears 1 time.\n",
      "Word 1401 (\"lawrenc\") appears 1 time.\n",
      "Word 1402 (\"layer\") appears 72 time.\n",
      "Word 1403 (\"lecun\") appears 2 time.\n",
      "Word 1404 (\"mitig\") appears 1 time.\n",
      "Word 1405 (\"mnist\") appears 4 time.\n",
      "Word 1406 (\"moment\") appears 3 time.\n",
      "Word 1407 (\"moor\") appears 1 time.\n",
      "Word 1408 (\"multiclass\") appears 2 time.\n",
      "Word 1409 (\"multimod\") appears 1 time.\n",
      "Word 1410 (\"net\") appears 1 time.\n",
      "Word 1411 (\"nonlinear\") appears 8 time.\n",
      "Word 1412 (\"nowak\") appears 1 time.\n",
      "Word 1413 (\"olivi\") appears 1 time.\n",
      "Word 1414 (\"osindero\") appears 1 time.\n",
      "Word 1415 (\"outcom\") appears 1 time.\n",
      "Word 1416 (\"particip\") appears 2 time.\n",
      "Word 1417 (\"percentag\") appears 1 time.\n",
      "Word 1418 (\"perceptron\") appears 4 time.\n",
      "Word 1419 (\"pereira\") appears 1 time.\n",
      "Word 1420 (\"primal\") appears 1 time.\n",
      "Word 1421 (\"protocol\") appears 1 time.\n",
      "Word 1422 (\"pseudo\") appears 2 time.\n",
      "Word 1423 (\"ranzato\") appears 2 time.\n",
      "Word 1424 (\"readili\") appears 1 time.\n",
      "Word 1425 (\"realiz\") appears 1 time.\n",
      "Word 1426 (\"roux\") appears 1 time.\n",
      "Word 1427 (\"salakhutdinov\") appears 1 time.\n",
      "Word 1428 (\"score\") appears 1 time.\n",
      "Word 1429 (\"semant\") appears 1 time.\n",
      "Word 1430 (\"sigmoid\") appears 1 time.\n",
      "Word 1431 (\"simplif\") appears 2 time.\n",
      "Word 1432 (\"softmax\") appears 3 time.\n",
      "Word 1433 (\"sole\") appears 1 time.\n",
      "Word 1434 (\"spheric\") appears 1 time.\n",
      "Word 1435 (\"stone\") appears 1 time.\n",
      "Word 1436 (\"stop\") appears 1 time.\n",
      "Word 1437 (\"subproblem\") appears 1 time.\n",
      "Word 1438 (\"svms\") appears 1 time.\n",
      "Word 1439 (\"swerski\") appears 1 time.\n",
      "Word 1440 (\"tion\") appears 1 time.\n",
      "Word 1441 (\"toronto\") appears 1 time.\n",
      "Word 1442 (\"trainabl\") appears 1 time.\n",
      "Word 1443 (\"unabl\") appears 1 time.\n",
      "Word 1444 (\"unlabel\") appears 6 time.\n",
      "Word 1445 (\"vandenbergh\") appears 1 time.\n",
      "Word 1446 (\"vincent\") appears 2 time.\n",
      "Word 1447 (\"wright\") appears 1 time.\n"
     ]
    }
   ],
   "source": [
    "bow_doc_4310 = bow_corpus[10]\n",
    "\n",
    "for i in range(len(bow_doc_4310)):\n",
    "    print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_doc_4310[i][0], dictionary[bow_doc_4310[i][0]], \n",
    "                                                     bow_doc_4310[i][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora, models\n",
    "\n",
    "tfidf = models.TfidfModel(bow_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_tfidf = tfidf[bow_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.013495872340591691),\n",
      " (1, 0.010897171360212933),\n",
      " (2, 0.014759341245638196),\n",
      " (3, 0.004329001016622904),\n",
      " (4, 0.014002903868499027),\n",
      " (5, 0.013707262510466781),\n",
      " (6, 0.003491164652545357),\n",
      " (7, 0.018921712939585653),\n",
      " (8, 0.014747783868130289),\n",
      " (9, 0.014199757922470156),\n",
      " (10, 0.008890289898277797),\n",
      " (11, 0.014235520827159736),\n",
      " (12, 0.029185644438191726),\n",
      " (13, 0.007272646610429487),\n",
      " (14, 0.04205201931799661),\n",
      " (15, 0.004324138104783362),\n",
      " (16, 0.010968353329539094),\n",
      " (17, 0.011825372746208415),\n",
      " (18, 0.008227709893299521),\n",
      " (19, 0.005837143356061971),\n",
      " (20, 0.00559333339324764),\n",
      " (21, 0.00736276514069092),\n",
      " (22, 0.008648276209566723),\n",
      " (23, 0.013766538821677627),\n",
      " (24, 0.008204923286253786),\n",
      " (25, 0.004876248923399829),\n",
      " (26, 0.005153224950881477),\n",
      " (27, 0.0571802669671754),\n",
      " (28, 0.013327605810536656),\n",
      " (29, 0.007312235553026063),\n",
      " (30, 0.018585179203472604),\n",
      " (31, 0.005423286140575489),\n",
      " (32, 0.0034068910201896585),\n",
      " (33, 0.006739681958038136),\n",
      " (34, 0.02325275923272507),\n",
      " (35, 0.26113576904057645),\n",
      " (36, 0.010412874151938088),\n",
      " (37, 0.01346223559918086),\n",
      " (38, 0.008683759582352723),\n",
      " (39, 0.06416157840087465),\n",
      " (40, 0.013787310036469299),\n",
      " (41, 0.007055479143944214),\n",
      " (42, 0.008559263998063183),\n",
      " (43, 0.016075105459924882),\n",
      " (44, 0.0033007743860554947),\n",
      " (45, 0.04129243758822191),\n",
      " (46, 0.007950733865817874),\n",
      " (47, 0.006421176350570402),\n",
      " (48, 0.006490928930525072),\n",
      " (49, 0.015875614800194733),\n",
      " (50, 0.011128281584553451),\n",
      " (51, 0.011978528045048353),\n",
      " (52, 0.009092776740622446),\n",
      " (53, 0.015165652262508215),\n",
      " (54, 0.01179693835883141),\n",
      " (55, 0.007220317525666049),\n",
      " (56, 0.016269858421726464),\n",
      " (57, 0.10234050239115058),\n",
      " (58, 0.005235546191422976),\n",
      " (59, 0.0038403474483349105),\n",
      " (60, 0.24122270057260778),\n",
      " (61, 0.01213699613564625),\n",
      " (62, 0.024895030862153382),\n",
      " (63, 0.02955254042971919),\n",
      " (64, 0.011071889709513904),\n",
      " (65, 0.003770926089987802),\n",
      " (66, 0.01569642692241983),\n",
      " (67, 0.012057075055518193),\n",
      " (68, 0.02130693404289734),\n",
      " (69, 0.00421369634170459),\n",
      " (70, 0.010485650158633139),\n",
      " (71, 0.12797142576222942),\n",
      " (72, 0.0064857372029846335),\n",
      " (73, 0.008474092592199273),\n",
      " (74, 0.004964856893345089),\n",
      " (75, 0.01380509352509579),\n",
      " (76, 0.04030034782714763),\n",
      " (77, 0.00444230086118976),\n",
      " (78, 0.005159056100673584),\n",
      " (79, 0.013056788452028822),\n",
      " (80, 0.0034871161762131727),\n",
      " (81, 0.005153224950881477),\n",
      " (82, 0.02612036112679417),\n",
      " (83, 0.04559472932253767),\n",
      " (84, 0.013258381679514606),\n",
      " (85, 0.044075345269844544),\n",
      " (86, 0.014992157903448815),\n",
      " (87, 0.008378659247818587),\n",
      " (88, 0.004232712832185323),\n",
      " (89, 0.009808562542202994),\n",
      " (90, 0.004538063219361536),\n",
      " (91, 0.013156473248234227),\n",
      " (92, 0.0036603188850774784),\n",
      " (93, 0.010411714562889167),\n",
      " (94, 0.006698633117279295),\n",
      " (95, 0.006030702933245933),\n",
      " (96, 0.014242173506655905),\n",
      " (97, 0.003174336737871926),\n",
      " (98, 0.02449155994229311),\n",
      " (99, 0.006649856441430253),\n",
      " (100, 0.004096603688639554),\n",
      " (101, 0.007413575709898061),\n",
      " (102, 0.015424754793689622),\n",
      " (103, 0.01498184652404752),\n",
      " (104, 0.009024279127092893),\n",
      " (105, 0.015197527544806346),\n",
      " (106, 0.006188755668123567),\n",
      " (107, 0.10866801741693197),\n",
      " (108, 0.015467944051790177),\n",
      " (109, 0.004204217696723923),\n",
      " (110, 0.03486630151178038),\n",
      " (111, 0.04505597484752597),\n",
      " (112, 0.006890588693839371),\n",
      " (113, 0.09154896460805793),\n",
      " (114, 0.01775728626965096),\n",
      " (115, 0.012801129857776691),\n",
      " (116, 0.003879865568030274),\n",
      " (117, 0.00972854814606391),\n",
      " (118, 0.004487411866393621),\n",
      " (119, 0.05387935587835278),\n",
      " (120, 0.006382880189693301),\n",
      " (121, 0.004838016857264517),\n",
      " (122, 0.0191944804637342),\n",
      " (123, 0.007244929405648768),\n",
      " (124, 0.04113818228328107),\n",
      " (125, 0.012057075055518193),\n",
      " (126, 0.015093688864968834),\n",
      " (127, 0.009906467115278535),\n",
      " (128, 0.016553648650320465),\n",
      " (129, 0.010064918381506803),\n",
      " (130, 0.006322266295744373),\n",
      " (131, 0.6039556803810816),\n",
      " (132, 0.02797614198422343),\n",
      " (133, 0.005349694666361437),\n",
      " (134, 0.01353800204820437),\n",
      " (135, 0.009873598590477598),\n",
      " (136, 0.0033910136619271056),\n",
      " (137, 0.006262446059895418),\n",
      " (138, 0.0043631871052511),\n",
      " (139, 0.007876097581237924),\n",
      " (140, 0.006424566025678492),\n",
      " (141, 0.015524002488133137),\n",
      " (142, 0.0046882098218517685),\n",
      " (143, 0.051204519431106765),\n",
      " (144, 0.034183485151619765),\n",
      " (145, 0.04225347017616746),\n",
      " (146, 0.12781721846209618),\n",
      " (147, 0.0053740936842541906),\n",
      " (148, 0.009535704510746307),\n",
      " (149, 0.00948230044006222),\n",
      " (150, 0.0908718792137325),\n",
      " (151, 0.06890588693839371),\n",
      " (152, 0.006853631255233391),\n",
      " (153, 0.006899120358768579),\n",
      " (154, 0.00544187072989798),\n",
      " (155, 0.013528978936532939),\n",
      " (156, 0.05070028031777355),\n",
      " (157, 0.011328936490474584),\n",
      " (158, 0.010696757419731898),\n",
      " (159, 0.010461348528639518),\n",
      " (160, 0.06294296809245874),\n",
      " (161, 0.005101076829641024),\n",
      " (162, 0.003383095626596993),\n",
      " (163, 0.010504766766066756),\n",
      " (164, 0.0322084291609973),\n",
      " (165, 0.010320519813711253),\n",
      " (166, 0.008414213553649495),\n",
      " (167, 0.06916842728277244),\n",
      " (168, 0.012083560377470551),\n",
      " (169, 0.007529972262491498),\n",
      " (170, 0.013541803095192342),\n",
      " (171, 0.015198243107512556),\n",
      " (172, 0.014432708399957346),\n",
      " (173, 0.006196071450698634),\n",
      " (174, 0.005510668412735179),\n",
      " (175, 0.02369189432292653),\n",
      " (176, 0.02988445240323835),\n",
      " (177, 0.003527763288115572),\n",
      " (178, 0.007046650725270673),\n",
      " (179, 0.019488878621505553),\n",
      " (180, 0.050060276972106334),\n",
      " (181, 0.0076719551442255935),\n",
      " (182, 0.035057533327497836),\n",
      " (183, 0.13169798643355718),\n",
      " (184, 0.012739389658181962),\n",
      " (185, 0.012801129857776691),\n",
      " (186, 0.3025195021358818),\n",
      " (187, 0.2660297932518287),\n",
      " (188, 0.0033476333121329983),\n",
      " (189, 0.010040358169429829),\n",
      " (190, 0.007950733865817874),\n",
      " (191, 0.012442616176967868),\n",
      " (192, 0.003762322122770873),\n",
      " (193, 0.004023209254971187),\n",
      " (194, 0.012863715839803952),\n",
      " (195, 0.0056709903095025225),\n",
      " (196, 0.05553277180956772),\n",
      " (197, 0.023354371063704273),\n",
      " (198, 0.03106121138581201),\n",
      " (199, 0.007813079958108548),\n",
      " (200, 0.02247629058315604),\n",
      " (201, 0.005561361917485523),\n",
      " (202, 0.05196608049706621),\n",
      " (203, 0.005235546191422976),\n",
      " (204, 0.0773317090171279),\n",
      " (205, 0.01569642692241983),\n",
      " (206, 0.01039332940632057),\n",
      " (207, 0.01839194203786046),\n",
      " (208, 0.007020267368551977),\n",
      " (209, 0.011952642960269808),\n",
      " (210, 0.0041664985537510245),\n",
      " (211, 0.0035155311382599227),\n",
      " (212, 0.015197527544806346),\n",
      " (213, 0.007771545988042969),\n",
      " (214, 0.013505398876747706),\n",
      " (215, 0.006439820470763692),\n",
      " (216, 0.0033007743860554947),\n",
      " (217, 0.0064443090847606565),\n",
      " (218, 0.0056709903095025225),\n",
      " (219, 0.012118072159631737),\n",
      " (220, 0.018879601559598086),\n",
      " (221, 0.014619732821837353),\n",
      " (222, 0.0315043903249517),\n",
      " (223, 0.0041664985537510245),\n",
      " (224, 0.00660960327141685),\n",
      " (225, 0.004204217696723923),\n",
      " (226, 0.007689593920887953),\n",
      " (227, 0.004329001016622904),\n",
      " (228, 0.007897298107642177),\n",
      " (229, 0.01250044866111082),\n",
      " (230, 0.010876729691918875),\n",
      " (231, 0.008110348679163108),\n",
      " (232, 0.011557265123792697),\n",
      " (233, 0.01281295479709716),\n",
      " (234, 0.03859114751941186),\n",
      " (235, 0.009857252579330898),\n",
      " (236, 0.019520771884194984),\n",
      " (237, 0.007235727579291545),\n",
      " (238, 0.01569642692241983),\n",
      " (239, 0.015358905013283708),\n",
      " (240, 0.020497704759144267),\n",
      " (241, 0.014125836089700772),\n",
      " (242, 0.0715275527193908),\n",
      " (243, 0.010534383065886926),\n",
      " (244, 0.006994035496055858),\n",
      " (245, 0.004143081253678279),\n",
      " (246, 0.018155808910024142),\n",
      " (247, 0.005410938281053969),\n",
      " (248, 0.007011506665499567),\n",
      " (249, 0.004285420032026462),\n",
      " (250, 0.006848167727585859),\n",
      " (251, 0.005723504741037398),\n",
      " (252, 0.1253047418012808),\n",
      " (253, 0.003212283012839246),\n",
      " (254, 0.004843459032109224),\n",
      " (255, 0.02715699944025913),\n",
      " (256, 0.015303781292886646),\n",
      " (257, 0.004082752120954202),\n",
      " (258, 0.009037896738491792),\n",
      " (259, 0.040438091748228815),\n",
      " (260, 0.009065254336656106),\n",
      " (261, 0.06298015548869909),\n",
      " (262, 0.05003257876817254),\n",
      " (263, 0.29791661895606547),\n",
      " (264, 0.0034709580506460296),\n",
      " (265, 0.009648285097358706),\n",
      " (266, 0.010471092382845952),\n",
      " (267, 0.012471440911333244),\n",
      " (268, 0.011000774557987567),\n",
      " (269, 0.005448082430707915),\n",
      " (270, 0.06638449958929545),\n",
      " (271, 0.011440412072636783),\n",
      " (272, 0.024327900454109114),\n",
      " (273, 0.007823522717493713),\n",
      " (274, 0.005657955478287067),\n",
      " (275, 0.039570572349392236),\n",
      " (276, 0.027533077643355254),\n",
      " (277, 0.008450046719628925),\n",
      " (278, 0.0071991044954732375),\n",
      " (279, 0.004185319199282781),\n",
      " (280, 0.010836118711258627),\n",
      " (281, 0.008147082037112131),\n",
      " (282, 0.010448708329723794),\n",
      " (283, 0.029837942900344902),\n",
      " (284, 0.008734523496196304),\n",
      " (285, 0.006247612588287304),\n",
      " (286, 0.022797364661268835),\n",
      " (287, 0.008378659247818587),\n",
      " (288, 0.004672446590888513),\n",
      " (289, 0.01139449505053992),\n",
      " (290, 0.007404264505499085),\n",
      " (291, 0.011193394875403686),\n",
      " (292, 0.008414213553649495),\n",
      " (293, 0.007771545988042969),\n",
      " (294, 0.020668739191467504),\n",
      " (295, 0.0066904674220905),\n",
      " (296, 0.01433837232898571),\n",
      " (297, 0.006101868005171018),\n",
      " (298, 0.031048004976266273),\n",
      " (299, 0.018219806453810314),\n",
      " (300, 0.004778576920490177),\n",
      " (301, 0.01682842710729899),\n",
      " (302, 0.01258859361849175),\n",
      " (303, 0.02776638590478386),\n",
      " (304, 0.008366869034199378),\n",
      " (305, 0.019012033633657353),\n",
      " (306, 0.005392478840822785),\n",
      " (307, 0.010461348528639518),\n",
      " (308, 0.006974232352426345),\n",
      " (309, 0.015467944051790177),\n",
      " (310, 0.012899702654558845),\n",
      " (311, 0.011122723834971046),\n",
      " (312, 0.013024037736571297),\n",
      " (313, 0.009319136606919331),\n",
      " (314, 0.008658587588968017),\n",
      " (315, 0.16064573071087726),\n",
      " (316, 0.03359588590812317),\n",
      " (317, 0.012796320309156133),\n",
      " (318, 0.006145105285999886),\n",
      " (319, 0.020569091141640534),\n",
      " (320, 0.00393309380399468),\n",
      " (321, 0.016296898156800296),\n",
      " (322, 0.014084490058722487)]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "for doc in corpus_tfidf:\n",
    "    pprint(doc)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics=10, id2word=dictionary, passes=2, workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.020*\"regret\" + 0.013*\"rank\" + 0.010*\"bandit\" + 0.009*\"action\" + 0.008*\"game\" + 0.007*\"player\" + 0.006*\"onlin\" + 0.006*\"round\" + 0.006*\"arm\" + 0.006*\"strategi\"\n",
      "Topic: 1 \n",
      "Words: 0.009*\"classifi\" + 0.009*\"variat\" + 0.008*\"label\" + 0.008*\"classif\" + 0.007*\"posterior\" + 0.007*\"kernel\" + 0.007*\"bayesian\" + 0.006*\"likelihood\" + 0.006*\"varianc\" + 0.006*\"convex\"\n",
      "Topic: 2 \n",
      "Words: 0.009*\"submodular\" + 0.009*\"rank\" + 0.004*\"deep\" + 0.004*\"layer\" + 0.004*\"memori\" + 0.004*\"rule\" + 0.004*\"kernel\" + 0.004*\"graph\" + 0.004*\"cluster\" + 0.004*\"convex\"\n",
      "Topic: 3 \n",
      "Words: 0.010*\"word\" + 0.008*\"domain\" + 0.006*\"layer\" + 0.006*\"item\" + 0.006*\"target\" + 0.006*\"deep\" + 0.005*\"classif\" + 0.005*\"label\" + 0.005*\"project\" + 0.004*\"recognit\"\n",
      "Topic: 4 \n",
      "Words: 0.014*\"layer\" + 0.009*\"neuron\" + 0.008*\"convolut\" + 0.008*\"visual\" + 0.007*\"deep\" + 0.006*\"activ\" + 0.005*\"encod\" + 0.005*\"transform\" + 0.005*\"attent\" + 0.005*\"dynam\"\n",
      "Topic: 5 \n",
      "Words: 0.018*\"graph\" + 0.014*\"cluster\" + 0.009*\"layer\" + 0.009*\"kernel\" + 0.008*\"convex\" + 0.007*\"deep\" + 0.005*\"edg\" + 0.005*\"norm\" + 0.005*\"variat\" + 0.005*\"unit\"\n",
      "Topic: 6 \n",
      "Words: 0.013*\"polici\" + 0.008*\"tensor\" + 0.007*\"rank\" + 0.007*\"spars\" + 0.006*\"group\" + 0.006*\"graph\" + 0.006*\"norm\" + 0.005*\"matric\" + 0.005*\"regress\" + 0.005*\"lemma\"\n",
      "Topic: 7 \n",
      "Words: 0.010*\"label\" + 0.009*\"agent\" + 0.007*\"kernel\" + 0.007*\"polici\" + 0.007*\"reward\" + 0.006*\"action\" + 0.006*\"graph\" + 0.005*\"activ\" + 0.005*\"dynam\" + 0.005*\"decis\"\n",
      "Topic: 8 \n",
      "Words: 0.017*\"convex\" + 0.008*\"smooth\" + 0.007*\"spars\" + 0.006*\"descent\" + 0.006*\"norm\" + 0.006*\"graph\" + 0.005*\"dual\" + 0.005*\"cluster\" + 0.005*\"coordin\" + 0.005*\"lemma\"\n",
      "Topic: 9 \n",
      "Words: 0.015*\"cluster\" + 0.014*\"label\" + 0.013*\"tree\" + 0.010*\"kernel\" + 0.006*\"queri\" + 0.005*\"margin\" + 0.005*\"latent\" + 0.005*\"layer\" + 0.005*\"classif\" + 0.005*\"graph\"\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "NLP m2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
